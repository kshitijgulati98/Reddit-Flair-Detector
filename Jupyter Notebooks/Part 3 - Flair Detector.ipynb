{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3 - Building a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import praw\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>locked</th>\n",
       "      <th>orig_content</th>\n",
       "      <th>text</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics</td>\n",
       "      <td>A polite request to all Indians here</td>\n",
       "      <td>396</td>\n",
       "      <td>0.96</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2ct57...</td>\n",
       "      <td>aaluinsonaout</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I don't know if it is the same situation in ot...</td>\n",
       "      <td>82</td>\n",
       "      <td>2020-04-16 16:27:46</td>\n",
       "      <td>Our society thrives on abuse of power. We let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>196</td>\n",
       "      <td>0.80</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>chillinvillain122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>First of all let me start by saying it was stu...</td>\n",
       "      <td>73</td>\n",
       "      <td>2020-04-04 18:28:28</td>\n",
       "      <td>Our country is just too far in at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politics</td>\n",
       "      <td>A new political party gave a full front page a...</td>\n",
       "      <td>730</td>\n",
       "      <td>0.97</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>aaluinsonaout</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>2020-03-08 12:06:11</td>\n",
       "      <td>This looks like an IIPM ad 1. Where did they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Hit by backlash over posts on lack of medical ...</td>\n",
       "      <td>407</td>\n",
       "      <td>0.97</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>2020-03-26 17:47:25</td>\n",
       "      <td>Well, Some people really deserve to die. ~~/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Politics in the time of corona: WB CM question...</td>\n",
       "      <td>85</td>\n",
       "      <td>0.87</td>\n",
       "      <td>https://www.timesnownews.com/india/article/pol...</td>\n",
       "      <td>ConcernedCitizen034</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-04-09 18:33:54</td>\n",
       "      <td>Oh FFS. \\n\\nYellow, Orange, Green, Red, all a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Covid-19: Kamal Nath says lockdown was delayed...</td>\n",
       "      <td>439</td>\n",
       "      <td>0.86</td>\n",
       "      <td>https://scroll.in/latest/958962/covid-19-kamal...</td>\n",
       "      <td>Ib90</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-04-13 09:26:58</td>\n",
       "      <td>*I has biggest IQ in the whole MP* - Probably...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Coronavirus Pandemic: Claps, Candles And Diya ...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.78</td>\n",
       "      <td>https://www.inventiva.co.in/stories/nandini/co...</td>\n",
       "      <td>hauntin</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-11 20:13:25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Contrary to a news report, Aadtiya Thackeray h...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g159jt...</td>\n",
       "      <td>proyo7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>On 7th April, The New Indian Express reported:...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-14 18:41:28</td>\n",
       "      <td>Ummm if there is no community transmission, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Coronavirus Outbreak: A database of books, per...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>https://www.firstpost.com/long-reads/coronavir...</td>\n",
       "      <td>Lister971191</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-12 07:43:10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>At least 36 people linked to Mysuru pharma clu...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.91</td>\n",
       "      <td>https://www.thenewsminute.com/article/least-36...</td>\n",
       "      <td>AlternativeDrop6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-11 20:20:06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2311 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            flair                                              title  score  \\\n",
       "0        Politics               A polite request to all Indians here    396   \n",
       "1        Politics  Pitting a community against a political party ...    196   \n",
       "2        Politics  A new political party gave a full front page a...    730   \n",
       "3        Politics  Hit by backlash over posts on lack of medical ...    407   \n",
       "4        Politics  Politics in the time of corona: WB CM question...     85   \n",
       "...           ...                                                ...    ...   \n",
       "2306  Coronavirus  Covid-19: Kamal Nath says lockdown was delayed...    439   \n",
       "2307  Coronavirus  Coronavirus Pandemic: Claps, Candles And Diya ...     19   \n",
       "2308  Coronavirus  Contrary to a news report, Aadtiya Thackeray h...     25   \n",
       "2309  Coronavirus  Coronavirus Outbreak: A database of books, per...      3   \n",
       "2310  Coronavirus  At least 36 people linked to Mysuru pharma clu...     18   \n",
       "\n",
       "      upvote_ratio                                                url  \\\n",
       "0             0.96  https://www.reddit.com/r/india/comments/g2ct57...   \n",
       "1             0.80  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2             0.97                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "3             0.97  https://theprint.in/india/hit-by-backlash-over...   \n",
       "4             0.87  https://www.timesnownews.com/india/article/pol...   \n",
       "...            ...                                                ...   \n",
       "2306          0.86  https://scroll.in/latest/958962/covid-19-kamal...   \n",
       "2307          0.78  https://www.inventiva.co.in/stories/nandini/co...   \n",
       "2308          0.84  https://www.reddit.com/r/india/comments/g159jt...   \n",
       "2309          0.71  https://www.firstpost.com/long-reads/coronavir...   \n",
       "2310          0.91  https://www.thenewsminute.com/article/least-36...   \n",
       "\n",
       "                   author  locked  orig_content  \\\n",
       "0           aaluinsonaout   False         False   \n",
       "1       chillinvillain122   False         False   \n",
       "2           aaluinsonaout   False         False   \n",
       "3               hipporama   False         False   \n",
       "4     ConcernedCitizen034   False         False   \n",
       "...                   ...     ...           ...   \n",
       "2306                 Ib90   False         False   \n",
       "2307              hauntin   False         False   \n",
       "2308               proyo7   False         False   \n",
       "2309         Lister971191   False         False   \n",
       "2310     AlternativeDrop6   False         False   \n",
       "\n",
       "                                                   text  comms_num  \\\n",
       "0     I don't know if it is the same situation in ot...         82   \n",
       "1     First of all let me start by saying it was stu...         73   \n",
       "2                                                   NaN        146   \n",
       "3                                                   NaN         67   \n",
       "4                                                   NaN         22   \n",
       "...                                                 ...        ...   \n",
       "2306                                                NaN         38   \n",
       "2307                                                NaN          1   \n",
       "2308  On 7th April, The New Indian Express reported:...          2   \n",
       "2309                                                NaN          0   \n",
       "2310                                                NaN          0   \n",
       "\n",
       "                timestamp                                           comments  \n",
       "0     2020-04-16 16:27:46   Our society thrives on abuse of power. We let...  \n",
       "1     2020-04-04 18:28:28   Our country is just too far in at the moment ...  \n",
       "2     2020-03-08 12:06:11   This looks like an IIPM ad 1. Where did they ...  \n",
       "3     2020-03-26 17:47:25   Well, Some people really deserve to die. ~~/s...  \n",
       "4     2020-04-09 18:33:54   Oh FFS. \\n\\nYellow, Orange, Green, Red, all a...  \n",
       "...                   ...                                                ...  \n",
       "2306  2020-04-13 09:26:58   *I has biggest IQ in the whole MP* - Probably...  \n",
       "2307  2020-04-11 20:13:25                                                NaN  \n",
       "2308  2020-04-14 18:41:28   Ummm if there is no community transmission, h...  \n",
       "2309  2020-04-12 07:43:10                                                NaN  \n",
       "2310  2020-04-11 20:20:06                                                NaN  \n",
       "\n",
       "[2311 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf=pd.read_csv('reddit_data.csv')\n",
    "dataf #the loaded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to preprocess the text for the comments,title,text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/54396405/how-can-i-preprocess-nlp-text-lowercase-remove-special-characters-remove-numb\n",
    "def preprocess_text(text):\n",
    "    text=str(text)\n",
    "    text=text.lower()# make the text lowercase\n",
    "    interval_char=re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    special_char= re.compile('[^0-9a-z #+_]')\n",
    "    text=interval_char.sub(' ',text)\n",
    "    text=special_char.sub('', text)\n",
    "    words=text.split()\n",
    "    text = ' '.join(i for i in words if i not in set(stopwords.words('english')))\n",
    "    return text\n",
    "#applying the preprocessing function to the 3 features\n",
    "dataf['title'] = dataf['title'].apply(preprocess_text)\n",
    "dataf['text'] = dataf['text'].apply(preprocess_text)\n",
    "dataf['comments'] = dataf['comments'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=dataf[\"title\"]\n",
    "comments=dataf[\"comments\"]\n",
    "text=dataf['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorizing the textual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we make 3 sepearate vectorizers for all 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2311, 62288) (2311, 34082) (2311, 6600)\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "count_vect_title = CountVectorizer()\n",
    "count_vect_text = CountVectorizer()\n",
    "count_vect_comments = CountVectorizer()\n",
    "title_token = count_vect_title.fit_transform(title)\n",
    "text_token = count_vect_text.fit_transform(text)\n",
    "comments_token= count_vect_comments.fit_transform(comments)\n",
    "print(comments_token.shape,\n",
    "text_token.shape,\n",
    "title_token.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After vectorizing we use TFIDF to get the features for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer_title = TfidfTransformer()\n",
    "tfidf_transformer_text = TfidfTransformer()\n",
    "tfidf_transformer_comments = TfidfTransformer()\n",
    "\n",
    "TITLE = tfidf_transformer_title.fit_transform(title_token)\n",
    "TEXT = tfidf_transformer_text.fit_transform(text_token)\n",
    "COMMENTS = tfidf_transformer_comments.fit_transform(comments_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataf[\"flair\"] #labels\n",
    "TITLE=pd.DataFrame(TITLE.toarray())\n",
    "TEXT=pd.DataFrame(TEXT.toarray())\n",
    "COMMENTS=pd.DataFrame(COMMENTS.toarray())\n",
    "\n",
    "X=pd.concat([TITLE,TEXT,COMMENTS,dataf['score'],dataf['upvote_ratio'],\n",
    "             dataf['locked'],dataf['comms_num']],axis=1)\n",
    "# X = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final X is (Title, Text, Comments, Score, Upvote_Ratio, Locked, comms_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into 67% Train and 33% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test a variety of ML models and choose the one with the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8152031454783748\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.81      0.82      0.81        76\n",
      "  Business/Finance       0.81      0.77      0.79        61\n",
      "       CAA-NRC-NPR       0.97      0.85      0.91        40\n",
      "       Coronavirus       0.81      0.89      0.84        61\n",
      "              Food       0.97      0.87      0.92        77\n",
      "     Non_Political       0.87      0.88      0.88        76\n",
      "       Photography       0.89      0.84      0.87        58\n",
      "    Policy/Economy       0.73      0.71      0.72        68\n",
      "          Politics       0.69      0.81      0.74        63\n",
      "         Scheduled       0.74      0.67      0.70        60\n",
      "Science/Technology       0.73      0.92      0.81        61\n",
      "            Sports       0.87      0.76      0.81        62\n",
      "\n",
      "          accuracy                           0.82       763\n",
      "         macro avg       0.82      0.81      0.82       763\n",
      "      weighted avg       0.82      0.82      0.82       763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('accuracy',accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier has an overall accuracy of 81.5%, we can see that is best at classifying the flair 'CAA-NRC-NPR' and 'Food' with high f1-scores of 0.91 and 0.92 respectively. It is least effective at classifying 'Policy/Economy' and 'Scheduled' with f1-scores of 0.72 and 0.70 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5504587155963303\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.51      0.67      0.58        76\n",
      "  Business/Finance       0.70      0.46      0.55        61\n",
      "       CAA-NRC-NPR       0.73      0.68      0.70        40\n",
      "       Coronavirus       0.78      0.51      0.61        61\n",
      "              Food       0.55      0.69      0.61        77\n",
      "     Non_Political       0.69      0.66      0.68        76\n",
      "       Photography       0.77      0.52      0.62        58\n",
      "    Policy/Economy       0.55      0.54      0.55        68\n",
      "          Politics       0.37      0.73      0.49        63\n",
      "         Scheduled       0.46      0.20      0.28        60\n",
      "Science/Technology       0.41      0.69      0.51        61\n",
      "            Sports       0.81      0.21      0.33        62\n",
      "\n",
      "          accuracy                           0.55       763\n",
      "         macro avg       0.61      0.55      0.54       763\n",
      "      weighted avg       0.60      0.55      0.54       763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = mlp.predict(X_test)\n",
    "\n",
    "print('accuracy',accuracy_score(y_pred1, y_test))\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP classifier gives an accuracy of 55 %. It performs best on the CAA-NRC-NPR flair and the worst on Scheduled with f1 scores of 0.70 and 0.28 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1913499344692005\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.21      0.82      0.34        76\n",
      "  Business/Finance       0.20      0.02      0.03        61\n",
      "       CAA-NRC-NPR       0.00      0.00      0.00        40\n",
      "       Coronavirus       0.00      0.00      0.00        61\n",
      "              Food       0.67      0.10      0.18        77\n",
      "     Non_Political       0.00      0.00      0.00        76\n",
      "       Photography       0.86      0.21      0.33        58\n",
      "    Policy/Economy       0.50      0.06      0.11        68\n",
      "          Politics       0.11      0.68      0.19        63\n",
      "         Scheduled       0.00      0.00      0.00        60\n",
      "Science/Technology       0.39      0.25      0.30        61\n",
      "            Sports       1.00      0.02      0.03        62\n",
      "\n",
      "          accuracy                           0.19       763\n",
      "         macro avg       0.33      0.18      0.13       763\n",
      "      weighted avg       0.34      0.19      0.13       763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kshitij/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NaiveBayes=MultinomialNB()\n",
    "NaiveBayes.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = NaiveBayes.predict(X_test)\n",
    "\n",
    "print('accuracy',accuracy_score(y_pred2, y_test))\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier performs poorly with an accuracy of 19%. It performs best on AskIndia and the worst on Coronavirus, Scheduled, Non-Political, CAA-NRC-NPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing feature extraction we find that our dataset has about 100,000 features(encoded text features) and 2311 data points. Since we have a large number of features which are 1/0 (encoded text), we can perform classification without dimensionality reduction. Had the number of features been more and non-binary we might have to explore the option of using PCA as well to reduce computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training multiple models we see that the performance of the Randomforest classifier is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we save the random forest classifier and the countvectorizer, TFIDF files for buliding our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('random_forest.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect_title, open('CountVectorizer_title.p', 'wb'))\n",
    "pickle.dump(count_vect_text, open('CountVectorizer_text.p', 'wb'))\n",
    "pickle.dump(count_vect_comments, open('CountVectorizer_comments.p', 'wb'))\n",
    "pickle.dump(tfidf_transformer_title, open('TFIDF_title.p', 'wb'))\n",
    "pickle.dump(tfidf_transformer_text, open('TFIDF_text.p', 'wb'))\n",
    "pickle.dump(tfidf_transformer_comments, open('TFIDF_comments.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
